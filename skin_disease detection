{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":9990570,"datasetId":4301853,"databundleVersionId":10257737,"isSourceIdPinned":false},{"sourceType":"datasetVersion","sourceId":5576091,"datasetId":3133102,"databundleVersionId":5650946,"isSourceIdPinned":false}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, VGG16, DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport json\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom tensorflow.keras.applications import EfficientNetB3, InceptionV3\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as efficient_preprocess\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\nfrom tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\nfrom tensorflow.keras.models import load_model\nimport random","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-08-10T04:45:25.382687Z","iopub.execute_input":"2025-08-10T04:45:25.382927Z","iopub.status.idle":"2025-08-10T04:45:38.890964Z","shell.execute_reply.started":"2025-08-10T04:45:25.382908Z","shell.execute_reply":"2025-08-10T04:45:38.890385Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-08-10 04:45:27.744982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754801127.936884      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754801127.989322      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"ascanipek/skin-diseases\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:30:46.475229Z","iopub.execute_input":"2025-08-09T19:30:46.475721Z","iopub.status.idle":"2025-08-09T19:30:50.659676Z","shell.execute_reply.started":"2025-08-09T19:30:46.475703Z","shell.execute_reply":"2025-08-09T19:30:50.658886Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/skin-diseases\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#base_path = '/kaggle/input/skindiseasedataset/SkinDisease/SkinDisease'\n\nbase_path='/kaggle/input/skin-diseases/kaggle'\n\ntrain_path = os.path.join(base_path, 'train')\ntest_path = os.path.join(base_path, 'test')\n\n# Listar clases\nclasses = sorted(os.listdir(train_path))\nnum_classes = len(classes)\n\n# Mostrar información\nprint(f\"Number of  total  clases: {num_classes}\")\nprint(\"Clases:\")\nfor cls in classes:\n    num_images = len(os.listdir(os.path.join(train_path, cls)))\n    print(f\"{cls}: {num_images} images\")\n","metadata":{"execution":{"iopub.status.busy":"2025-08-10T04:45:38.892074Z","iopub.execute_input":"2025-08-10T04:45:38.892761Z","iopub.status.idle":"2025-08-10T04:45:39.258435Z","shell.execute_reply.started":"2025-08-10T04:45:38.892734Z","shell.execute_reply":"2025-08-10T04:45:39.257672Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of  total  clases: 6\nClases:\n1. Enfeksiyonel: 6000 images\n2. Ekzama: 4070 images\n3. Akne: 2149 images\n4. Pigment: 1020 images\n5. Benign: 10888 images\n6. Malign: 6783 images\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# ⬛ IMAGE SETTINGS\nIMG_SIZE = 224\nBATCH_SIZE = 32\nEPOCHS = 30","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T04:45:40.629315Z","iopub.execute_input":"2025-08-10T04:45:40.629755Z","iopub.status.idle":"2025-08-10T04:45:40.633496Z","shell.execute_reply.started":"2025-08-10T04:45:40.629735Z","shell.execute_reply":"2025-08-10T04:45:40.632793Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n\ndef get_generators(preprocess_func):\n    train_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_func,\n        rotation_range=25,\n        zoom_range=0.2,\n        width_shift_range=0.15,\n        height_shift_range=0.15,\n        shear_range=0.1,\n        horizontal_flip=True,\n        fill_mode='nearest',\n        brightness_range=[0.8, 1.2]\n\n    )\n\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_path,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical'\n    )\n\n    test_generator = test_datagen.flow_from_directory(\n        test_path,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    return train_generator, test_generator","metadata":{"execution":{"iopub.status.busy":"2025-08-10T04:45:43.910428Z","iopub.execute_input":"2025-08-10T04:45:43.910729Z","iopub.status.idle":"2025-08-10T04:45:43.916043Z","shell.execute_reply.started":"2025-08-10T04:45:43.910708Z","shell.execute_reply":"2025-08-10T04:45:43.915209Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Visualization Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nclass_counts = {cls: len(os.listdir(os.path.join(train_path, cls))) for cls in classes}\ndf_counts = pd.DataFrame(list(class_counts.items()), columns=['Clase', 'count'])\ndf_counts = df_counts.sort_values(by='count', ascending=False)\n\n# Visualizar\nimport seaborn as sns\nplt.figure(figsize=(12,6))\n\nsns.barplot(x='count', y='Clase', data=df_counts)\n\nplt.title(\"Count of images per class\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-08-10T04:45:53.439137Z","iopub.execute_input":"2025-08-10T04:45:53.439437Z","iopub.status.idle":"2025-08-10T04:45:53.725133Z","shell.execute_reply.started":"2025-08-10T04:45:53.439416Z","shell.execute_reply":"2025-08-10T04:45:53.724561Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"#  Fine-Tuning","metadata":{}},{"cell_type":"code","source":"def train_model(base_model, preprocess_func, model_name):\n    print(f\"\\n  {model_name} \")\n\n    train_generator, test_generator = get_generators(preprocess_func)\n     # Compute class weights\n    class_weights = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_generator.classes),\n        y=train_generator.classes\n    )\n    class_weights = dict(enumerate(class_weights))\n    print(\"Class Weights:\", class_weights)\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    '''\n    # Fine-tuning complet\n    for layer in base_model.layers[:-50]:\n        layer.trainable = False\n    for layer in base_model.layers[-50:]:\n        layer.trainable = True\n        \n    '''\n    for layer in base_model.layers:\n         layer.trainable = True\n    \n\n\n    model.compile(optimizer=Adam(learning_rate=1e-4),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    # Callbacks\n    checkpoint = ModelCheckpoint(f\"{model_name}.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n\n    # Entrenamiento\n    history = model.fit(\n        train_generator,\n        validation_data=test_generator,\n        epochs=EPOCHS,\n        callbacks=[early_stop, checkpoint, reduce_lr],\n        class_weight=class_weights,\n        verbose=1\n    )\n\n    # Guardar historial\n    with open(f\"{model_name}_history.json\", \"w\") as f:\n        json.dump(history.history, f)\n\n    # Evaluación\n    loss, acc = model.evaluate(test_generator)\n    print(f\"{model_name} - Precision final: {acc:.4f} - Loss: {loss:.4f}\")\n\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2025-08-10T04:45:57.201492Z","iopub.execute_input":"2025-08-10T04:45:57.201806Z","iopub.status.idle":"2025-08-10T04:45:57.210086Z","shell.execute_reply.started":"2025-08-10T04:45:57.201783Z","shell.execute_reply":"2025-08-10T04:45:57.209353Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# **Models**","metadata":{}},{"cell_type":"markdown","source":"# **ResNet50**","metadata":{}},{"cell_type":"code","source":"# Entrenar ResNet50\nresnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nresnet_trained, history_resnet = train_model(resnet_model, resnet_preprocess, 'ResNet50')","metadata":{"execution":{"iopub.status.busy":"2025-08-09T19:33:40.945978Z","iopub.execute_input":"2025-08-09T19:33:40.946743Z","iopub.status.idle":"2025-08-09T21:45:52.090273Z","shell.execute_reply.started":"2025-08-09T19:33:40.946714Z","shell.execute_reply":"2025-08-09T21:45:52.089638Z"},"trusted":true},"outputs":[{"name":"stderr","text":"I0000 00:00:1754768021.712978      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n\n  ResNet50 \nFound 30909 images belonging to 6 classes.\nFound 3928 images belonging to 6 classes.\nClass Weights: {0: 0.8585833333333334, 1: 1.2657248157248158, 2: 2.3982774674115457, 3: 5.050490196078432, 4: 0.47313556208670093, 5: 0.7594722099366062}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1754768110.838379      99 service.cc:148] XLA service 0x7c25b8004ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1754768110.839075      99 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1754768115.523643      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/966\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:53:11\u001b[0m 74s/step - accuracy: 0.1250 - loss: 1.6007","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1754768134.131678      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.6116 - loss: 1.0064\nEpoch 1: val_accuracy improved from -inf to 0.66421, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 896ms/step - accuracy: 0.6116 - loss: 1.0063 - val_accuracy: 0.6642 - val_loss: 0.9063 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.7485 - loss: 0.6634\nEpoch 2: val_accuracy improved from 0.66421 to 0.74847, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 569ms/step - accuracy: 0.7485 - loss: 0.6634 - val_accuracy: 0.7485 - val_loss: 0.6692 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - accuracy: 0.7911 - loss: 0.5426\nEpoch 3: val_accuracy improved from 0.74847 to 0.77775, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 554ms/step - accuracy: 0.7911 - loss: 0.5427 - val_accuracy: 0.7777 - val_loss: 0.6392 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.8121 - loss: 0.4776\nEpoch 4: val_accuracy improved from 0.77775 to 0.80015, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 564ms/step - accuracy: 0.8121 - loss: 0.4776 - val_accuracy: 0.8002 - val_loss: 0.5652 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.8358 - loss: 0.4168\nEpoch 5: val_accuracy improved from 0.80015 to 0.80372, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 559ms/step - accuracy: 0.8358 - loss: 0.4168 - val_accuracy: 0.8037 - val_loss: 0.5879 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.8531 - loss: 0.3754\nEpoch 6: val_accuracy improved from 0.80372 to 0.82561, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 544ms/step - accuracy: 0.8531 - loss: 0.3754 - val_accuracy: 0.8256 - val_loss: 0.5198 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.8696 - loss: 0.3254\nEpoch 7: val_accuracy improved from 0.82561 to 0.82790, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 549ms/step - accuracy: 0.8696 - loss: 0.3254 - val_accuracy: 0.8279 - val_loss: 0.5268 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.8853 - loss: 0.2873\nEpoch 8: val_accuracy improved from 0.82790 to 0.82841, saving model to ResNet50.h5\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 547ms/step - accuracy: 0.8853 - loss: 0.2873 - val_accuracy: 0.8284 - val_loss: 0.5615 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.9173 - loss: 0.1955\nEpoch 9: val_accuracy improved from 0.82841 to 0.88289, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 545ms/step - accuracy: 0.9173 - loss: 0.1955 - val_accuracy: 0.8829 - val_loss: 0.3887 - learning_rate: 5.0000e-05\nEpoch 10/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.9399 - loss: 0.1464\nEpoch 10: val_accuracy improved from 0.88289 to 0.88951, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 555ms/step - accuracy: 0.9399 - loss: 0.1464 - val_accuracy: 0.8895 - val_loss: 0.3823 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.9458 - loss: 0.1269\nEpoch 11: val_accuracy did not improve from 0.88951\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 542ms/step - accuracy: 0.9458 - loss: 0.1269 - val_accuracy: 0.8857 - val_loss: 0.3911 - learning_rate: 5.0000e-05\nEpoch 12/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.9514 - loss: 0.1134\nEpoch 12: val_accuracy did not improve from 0.88951\n\nEpoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 559ms/step - accuracy: 0.9514 - loss: 0.1134 - val_accuracy: 0.8801 - val_loss: 0.4260 - learning_rate: 5.0000e-05\nEpoch 13/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.9633 - loss: 0.0869\nEpoch 13: val_accuracy improved from 0.88951 to 0.89995, saving model to ResNet50.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 551ms/step - accuracy: 0.9633 - loss: 0.0869 - val_accuracy: 0.8999 - val_loss: 0.3907 - learning_rate: 2.5000e-05\nEpoch 14/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.9739 - loss: 0.0630\nEpoch 14: val_accuracy did not improve from 0.89995\n\nEpoch 14: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 538ms/step - accuracy: 0.9739 - loss: 0.0630 - val_accuracy: 0.8931 - val_loss: 0.4081 - learning_rate: 2.5000e-05\n\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - accuracy: 0.8827 - loss: 0.4333\nResNet50 - Precision final: 0.8895 - Loss: 0.3823\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **DenseNet121**","metadata":{}},{"cell_type":"code","source":"# Entrenar DenseNet121\ndensenet_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\ndensenet_trained, history_densenet = train_model(densenet_model, densenet_preprocess, 'DenseNet121')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T21:55:45.675598Z","iopub.execute_input":"2025-08-09T21:55:45.676255Z","iopub.status.idle":"2025-08-10T00:38:02.655587Z","shell.execute_reply.started":"2025-08-09T21:55:45.676229Z","shell.execute_reply":"2025-08-10T00:38:02.654980Z"}},"outputs":[{"name":"stdout","text":"\n  DenseNet121 \nFound 30909 images belonging to 6 classes.\nFound 3928 images belonging to 6 classes.\nClass Weights: {0: 0.8585833333333334, 1: 1.2657248157248158, 2: 2.3982774674115457, 3: 5.050490196078432, 4: 0.47313556208670093, 5: 0.7594722099366062}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.5983 - loss: 1.0326\nEpoch 1: val_accuracy improved from -inf to 0.74822, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m776s\u001b[0m 635ms/step - accuracy: 0.5984 - loss: 1.0325 - val_accuracy: 0.7482 - val_loss: 0.6689 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.7489 - loss: 0.6605\nEpoch 2: val_accuracy improved from 0.74822 to 0.76247, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 537ms/step - accuracy: 0.7489 - loss: 0.6605 - val_accuracy: 0.7625 - val_loss: 0.6321 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.7869 - loss: 0.5364\nEpoch 3: val_accuracy did not improve from 0.76247\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 538ms/step - accuracy: 0.7869 - loss: 0.5364 - val_accuracy: 0.7477 - val_loss: 0.6768 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.8162 - loss: 0.4617\nEpoch 4: val_accuracy improved from 0.76247 to 0.81034, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 542ms/step - accuracy: 0.8162 - loss: 0.4617 - val_accuracy: 0.8103 - val_loss: 0.5355 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.8442 - loss: 0.3965\nEpoch 5: val_accuracy improved from 0.81034 to 0.83478, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 544ms/step - accuracy: 0.8442 - loss: 0.3965 - val_accuracy: 0.8348 - val_loss: 0.4668 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.8643 - loss: 0.3368\nEpoch 6: val_accuracy did not improve from 0.83478\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 545ms/step - accuracy: 0.8643 - loss: 0.3368 - val_accuracy: 0.8136 - val_loss: 0.5055 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - accuracy: 0.8776 - loss: 0.3017\nEpoch 7: val_accuracy did not improve from 0.83478\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 539ms/step - accuracy: 0.8776 - loss: 0.3017 - val_accuracy: 0.8294 - val_loss: 0.4983 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.9151 - loss: 0.2041\nEpoch 8: val_accuracy improved from 0.83478 to 0.88416, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 544ms/step - accuracy: 0.9151 - loss: 0.2041 - val_accuracy: 0.8842 - val_loss: 0.3624 - learning_rate: 5.0000e-05\nEpoch 9/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.9369 - loss: 0.1480\nEpoch 9: val_accuracy improved from 0.88416 to 0.88697, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 549ms/step - accuracy: 0.9369 - loss: 0.1480 - val_accuracy: 0.8870 - val_loss: 0.3630 - learning_rate: 5.0000e-05\nEpoch 10/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.9459 - loss: 0.1274\nEpoch 10: val_accuracy did not improve from 0.88697\n\nEpoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 542ms/step - accuracy: 0.9459 - loss: 0.1274 - val_accuracy: 0.8814 - val_loss: 0.3926 - learning_rate: 5.0000e-05\nEpoch 11/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.9573 - loss: 0.0993\nEpoch 11: val_accuracy improved from 0.88697 to 0.90453, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 533ms/step - accuracy: 0.9573 - loss: 0.0993 - val_accuracy: 0.9045 - val_loss: 0.3376 - learning_rate: 2.5000e-05\nEpoch 12/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - accuracy: 0.9660 - loss: 0.0810\nEpoch 12: val_accuracy improved from 0.90453 to 0.90631, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 540ms/step - accuracy: 0.9660 - loss: 0.0810 - val_accuracy: 0.9063 - val_loss: 0.3564 - learning_rate: 2.5000e-05\nEpoch 13/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.9719 - loss: 0.0703\nEpoch 13: val_accuracy did not improve from 0.90631\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 536ms/step - accuracy: 0.9719 - loss: 0.0703 - val_accuracy: 0.9020 - val_loss: 0.3773 - learning_rate: 2.5000e-05\nEpoch 14/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9768 - loss: 0.0564\nEpoch 14: val_accuracy improved from 0.90631 to 0.91930, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 555ms/step - accuracy: 0.9768 - loss: 0.0564 - val_accuracy: 0.9193 - val_loss: 0.3225 - learning_rate: 1.2500e-05\nEpoch 15/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.9786 - loss: 0.0490\nEpoch 15: val_accuracy did not improve from 0.91930\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 540ms/step - accuracy: 0.9786 - loss: 0.0490 - val_accuracy: 0.9190 - val_loss: 0.3283 - learning_rate: 1.2500e-05\nEpoch 16/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.9792 - loss: 0.0515\nEpoch 16: val_accuracy did not improve from 0.91930\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 542ms/step - accuracy: 0.9792 - loss: 0.0515 - val_accuracy: 0.9180 - val_loss: 0.3248 - learning_rate: 1.2500e-05\nEpoch 17/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.9844 - loss: 0.0426\nEpoch 17: val_accuracy improved from 0.91930 to 0.92261, saving model to DenseNet121.h5\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 543ms/step - accuracy: 0.9844 - loss: 0.0426 - val_accuracy: 0.9226 - val_loss: 0.3241 - learning_rate: 6.2500e-06\nEpoch 18/30\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step - accuracy: 0.9853 - loss: 0.0369\nEpoch 18: val_accuracy improved from 0.92261 to 0.92490, saving model to DenseNet121.h5\n\nEpoch 18: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m966/966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 574ms/step - accuracy: 0.9853 - loss: 0.0369 - val_accuracy: 0.9249 - val_loss: 0.3256 - learning_rate: 6.2500e-06\n\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - accuracy: 0.9206 - loss: 0.3390\nDenseNet121 - Precision final: 0.9193 - Loss: 0.3225\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# **VGG16**","metadata":{}},{"cell_type":"code","source":"# Entrenar VGG16\nvgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nvgg_trained, history_vgg = train_model(vgg_model, vgg_preprocess, 'VGG16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T04:46:12.725398Z","iopub.execute_input":"2025-08-10T04:46:12.725679Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1754801173.633381      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1754801173.634112      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n\n  VGG16 \nFound 30909 images belonging to 6 classes.\nFound 3928 images belonging to 6 classes.\nClass Weights: {0: 0.8585833333333334, 1: 1.2657248157248158, 2: 2.3982774674115457, 3: 5.050490196078432, 4: 0.47313556208670093, 5: 0.7594722099366062}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1754801194.679273      99 service.cc:148] XLA service 0x78af0c003800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1754801194.680225      99 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1754801194.680252      99 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1754801195.417008      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1754801225.636518      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m414/966\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:34\u001b[0m 714ms/step - accuracy: 0.2616 - loss: 1.7466","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **EfficientNetB3**","metadata":{}},{"cell_type":"code","source":"efficient_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nefficientnet_trained, history_eff = train_model(efficient_model, efficient_preprocess, 'EfficientNetB3')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **InceptionV3**","metadata":{}},{"cell_type":"code","source":"inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\ninception_trained, history_incep = train_model(inception_model, inception_preprocess, 'InceptionV3')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **summary of architecture and model parameters**","metadata":{}},{"cell_type":"code","source":"def show_model_parameters(models):\n  \n    for model_path, preprocess_func, model_name in models:\n        print(\"=\" * 70)\n        print(f\" Model : {model_name}\")\n        print(\"=\" * 70)\n        model = load_model(model_path)\n        model.summary()\n        print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_model_parameters([\n    (\"ResNet50.h5\", resnet_preprocess, \"ResNet50\"),\n    (\"DenseNet121.h5\", densenet_preprocess, \"DenseNet121\"),\n    (\"VGG16.h5\", vgg_preprocess, \"VGG16\"),\n    (\"EfficientNetB3.h5\", efficient_preprocess, \"EfficientNetB3\"),\n    (\"InceptionV3.h5\", inception_preprocess, \"InceptionV3\")\n])\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Metrics**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef evaluate_model(h5_model_name,  preprocess_func, model_name):\n    print(\"=\" * 60)\n    print(f\" Evaluation of models: {model_name}\")\n    print(\"=\" * 60)\n\n    # Cargar modelo\n    model = load_model(h5_model_name)\n\n    # Cargar test generator sin shuffle\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n    test_generator_eval = test_datagen.flow_from_directory(\n        test_path,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    # Predicciones\n    y_pred = np.argmax(model.predict(test_generator_eval), axis=1)\n    y_true = test_generator_eval.classes\n    class_names = list(test_generator_eval.class_indices.keys())\n\n    # Reporte por clase\n    print(\"\\n Report of classification per class:\\n\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n\n    # Precisión global\n    acc = accuracy_score(y_true, y_pred)\n    print(f\"Total model accuracy{model_name}: {acc * 100:.2f}%\\n\\n\")\n\n    return acc\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(\"ResNet50.h5\", resnet_preprocess, \"ResNet50\")\nevaluate_model(\"DenseNet121.h5\", densenet_preprocess, \"DenseNet121\")\nevaluate_model(\"VGG16.h5\", vgg_preprocess, \"VGG16\")\nevaluate_model(\"EfficientNetB3.h5\", efficient_preprocess, \"EfficientNetB3\")\nevaluate_model(\"InceptionV3.h5\", inception_preprocess, \"InceptionV3\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Confusion matrix**","metadata":{}},{"cell_type":"code","source":"\n#Function for all models\ndef show_confusion_matrix(y_true, y_pred, class_names, model_name):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names,\n                yticklabels=class_names)\n    plt.title(f' Confusion Matrix - {model_name}', fontsize=16)\n    plt.xlabel('Predicción')\n    plt.ylabel('Real')\n    plt.xticks(rotation=90)\n    plt.yticks(rotation=0)\n    plt.tight_layout()\n    plt.show()\n\n\n# List of models and their preprocessing functions\nmodels = [\n    (\"ResNet50.h5\", resnet_preprocess, \"ResNet50\"),\n    (\"DenseNet121.h5\", densenet_preprocess, \"DenseNet121\"),\n    (\"VGG16.h5\", vgg_preprocess, \"VGG16\"),\n    (\"EfficientNetB3.h5\", efficient_preprocess, \"EfficientNetB3\"),\n    (\"InceptionV3.h5\", inception_preprocess, \"InceptionV3\")\n]\n\n# \nfor h5_name, preprocess_func, model_name in models:\n    print(f\" Evaluated {model_name}...\")\n    model = load_model(h5_name)\n\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n    test_generator = test_datagen.flow_from_directory(\n        test_path,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    y_true = test_generator.classes\n    y_pred = np.argmax(model.predict(test_generator), axis=1)\n    class_names = list(test_generator.class_indices.keys())\n\n    show_confusion_matrix(y_true, y_pred, class_names, model_name)\n\n\n# Acurracy & Loss","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_history(history, model_name):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(len(acc))\n\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Train Accuracy')\n    plt.plot(epochs_range, val_acc, label='Val Accuracy')\n    plt.title(f'{model_name} - Accuracy')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Train Loss')\n    plt.plot(epochs_range, val_loss, label='Val Loss')\n    plt.title(f'{model_name} - Loss')\n    plt.legend()\n    \n    plt.show()\n\nplot_history(history_resnet, \"ResNet50\")\nplot_history(history_densenet, \"DenseNet121\")\nplot_history(history_vgg, \"VGG16\")\nplot_history(history_eff, \"EfficientNetB3\")\nplot_history(history_incep, \"InceptionV3\")\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.458Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **ROC**","metadata":{}},{"cell_type":"code","source":"def get_multiclass_roc(model_path, preprocess_func, model_name):\n    model = load_model(model_path)\n\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n    test_generator = test_datagen.flow_from_directory(\n        test_path,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    y_true = test_generator.classes\n    y_score = model.predict(test_generator, verbose=0)\n    class_names = list(test_generator.class_indices.keys())\n\n    \n    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(len(class_names)):\n        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Micro-average\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_score.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n    return fpr[\"micro\"], tpr[\"micro\"], roc_auc[\"micro\"], model_name","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def graph_roc_models(models_info):\n    plt.figure(figsize=(10, 8))\n\n    for model_path, preprocess_func, model_name in models_info:\n        fpr, tpr, auc_score, name = get_multiclass_roc(model_path, preprocess_func, model_name)\n        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate (FPR)')\n    plt.ylabel('True Positive Rate (TPR)')\n    plt.title('ROC Curve - Model Comparison (micro-average)')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = [\n    (\"ResNet50.h5\", resnet_preprocess, \"ResNet50\"),\n    (\"DenseNet121.h5\", densenet_preprocess, \"DenseNet121\"),\n    (\"VGG16.h5\", vgg_preprocess, \"VGG16\"),\n    (\"EfficientNetB3.h5\", efficient_preprocess, \"EfficientNetB3\"),\n    (\"InceptionV3.h5\", inception_preprocess, \"InceptionV3\")\n]\n\ngraph_roc_models(models)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.459Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Show 4 predictions per model**","metadata":{}},{"cell_type":"code","source":"def undo_preprocessing(img_array):\n    img = img_array.copy()\n\n    # De [-1,1] a [0,1]\n    if img.min() < 0:\n        img = (img + 1) / 2\n    # De [0,255] a [0,1]\n    elif img.max() > 1:\n        img = img / 255.0\n\n    return np.clip(img, 0, 1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_predictions(modelo_h5, preprocess_func, model_name):\n    print(f\"\\nShowing example predictions for {model_name}...\\n\")\n\n    model = load_model(modelo_h5)\n\n    # Generator without shuffle\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n    test_generator = test_datagen.flow_from_directory(\n        test_path,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=1,  # 1 image at a time to make access easier\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    class_names = list(test_generator.class_indices.keys())\n    x_test = []\n    y_true = []\n    filepaths = []\n\n    # Collect all images\n    for i in range(len(test_generator)):\n        img, label = test_generator[i]\n        x_test.append(img[0])\n        y_true.append(np.argmax(label[0]))\n        filepaths.append(test_generator.filepaths[i])\n\n    x_test = np.array(x_test)\n    y_true = np.array(y_true)\n\n    # Get predictions\n    y_pred_prob = model.predict(x_test, verbose=0)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n\n    # Choose 4 random indices\n    indices = random.sample(range(len(x_test)), 4)\n\n    # Show images\n    plt.figure(figsize=(12, 6))\n    for i, idx in enumerate(indices):\n        plt.subplot(1, 4, i + 1)\n        plt.imshow(undo_preprocessing(x_test[idx]))\n        real = class_names[y_true[idx]]\n        pred = class_names[y_pred[idx]]\n        color = 'green' if real == pred else 'red'\n        plt.title(f\"Actual: {real}\\nPredicted: {pred}\", color=color, fontsize=10)\n        plt.axis('off')\n    plt.suptitle(f\"Predictions - {model_name}\", fontsize=14)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_predictions(\"ResNet50.h5\", resnet_preprocess, \"ResNet50\")\nshow_predictions(\"DenseNet121.h5\", densenet_preprocess, \"DenseNet121\")\nshow_predictions(\"VGG16.h5\", vgg_preprocess, \"VGG16\")\nshow_predictions(\"EfficientNetB3.h5\", efficient_preprocess, \"EfficientNetB3\")\nshow_predictions(\"InceptionV3.h5\", inception_preprocess, \"InceptionV3\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-10T04:25:08.459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}